{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ophthalmic Agentic AI System\n",
        "## Multi-Agent Diabetic Retinopathy Detection with Explainable AI & Clinical Governance\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/saman-emami/dr-agent/blob/main/test_and_visualize.ipynb)\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Project Overview\n",
        "\n",
        "This project implements a **mini-agentic AI system** for automated diabetic retinopathy (DR) detection and analysis in retinal fundus images. The system combines vision models with chain-of-thought reasoning and governance policies to deliver clinically interpretable predictions.\n",
        "\n",
        "### üéØ Key Features\n",
        "\n",
        "- **üî¨ Vision Agent (RetinaNet)**: Automated DR stage classification (0-4 severity levels) with Grad-CAM explainability heatmaps\n",
        "- **üß† Reasoner Agent**: Chain-of-thought clinical reasoning with evidence-based recommendations using LLM or rule-based logic\n",
        "- **‚öñÔ∏è Governor Agent**: Policy validation, consistency checking, and comprehensive audit trail generation\n",
        "- **üé≠ Orchestrator**: ReAct-based coordination with automatic fallback mechanisms for robustness"
      ],
      "metadata": {
        "id": "yqfEALElvD-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the repo"
      ],
      "metadata": {
        "id": "h4bD-EUYrODx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X-x7kXrqacC",
        "outputId": "1ee647ee-f635-4a15-e9ef-7c602ec3028f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dr-agent'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 16 (delta 3), reused 15 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (16/16), 22.85 KiB | 4.57 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "!git clone https://github.com/saman-emami/dr-agent\n",
        "repo_name = \"dr-agent\"\n",
        "!mv /content/{repo_name}/src/* /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# initialize the agent"
      ],
      "metadata": {
        "id": "kjMppzZXsCaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vision_agent import VisionAgent\n",
        "from reasoner_agent import ReasonerAgent\n",
        "from governor_agent import GovernorAgent\n",
        "from orchestrator import ReactOrchestrator\n",
        "\n",
        "vision_agent = VisionAgent()\n",
        "\n",
        "reasoner_agent = ReasonerAgent()\n",
        "\n",
        "governor_agent = GovernorAgent()\n",
        "\n",
        "orchestrator = ReactOrchestrator(\n",
        "    vision_agent=vision_agent,\n",
        "    reasoner_agent=reasoner_agent,\n",
        "    governor_agent=governor_agent,\n",
        ")"
      ],
      "metadata": {
        "id": "H2ErAwZwr_aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def visualize_ophthalmology_analysis(result, image_path):\n",
        "    \"\"\"\n",
        "    Visualize and print ophthalmic AI analysis results.\n",
        "\n",
        "    Args:\n",
        "        result: Object containing final_result with prediction data\n",
        "        image_path: Path to the original retinal image\n",
        "    \"\"\"\n",
        "\n",
        "    final_result = result.final_result\n",
        "    prediction = final_result['prediction']\n",
        "    confidence = final_result['confidence']\n",
        "    reasoning = final_result['reasoning']\n",
        "    explanation = final_result['explanation']\n",
        "    governance = final_result['governance']\n",
        "    key_regions = final_result['key_regions']\n",
        "\n",
        "    print(f\"\\nüè• PREDICTION:   {prediction}\")\n",
        "    print(f\"üìà CONFIDENCE:   {confidence:.1%}\")\n",
        "    print(f\"‚úì VALIDATED:     {governance['validated']}\")\n",
        "    print(f\"\\nREASONING:\\n{reasoning}\\n\")\n",
        "    print(f\"EXPLANATION:\\n{explanation}\")\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    gs = GridSpec(2, 2, figure=fig, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    img = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(\"Original Retinal Image\", fontsize=12, fontweight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    ax2.imshow(key_regions)\n",
        "    ax2.set_title(f\"Grad-CAM Attention Map\\nConfidence: {confidence:.1%}\",\n",
        "                  fontsize=12, fontweight='bold')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    fig.suptitle(f\"Ophthalmic AI Analysis - {prediction}\",\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Uub83eIPuc8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_path = \"/content/dr-agent/images\"\n",
        "file_names = [\n",
        "    \"51269b77d312.png\",\n",
        "    \"0bf37ca3156a.png\",\n",
        "    \"1a7e3356b39c.png\",\n",
        "    \"2a099b247b10.png\",\n",
        "    \"687759336b0d.png\",\n",
        "    \"0ceb222f6629.png\",\n",
        "    \"1e143fa3de57.png\",\n",
        "    \"2a3378bcfbcc.png\",\n",
        "    \"0e0fc1d9810c.png\",\n",
        "    \"1e4650743fa2.png\",\n",
        "    \"2a47e5b21791.png\",\n",
        "]\n",
        "\n",
        "for file_name in file_names:\n",
        "    full_path = f\"{test_images_path}/{file_name}\"\n",
        "    print(f\"Analysing: {file_name}\")\n",
        "    result = orchestrator.execute(file_name)\n",
        "    visualize_ophthalmology_analysis(result,file_name)"
      ],
      "metadata": {
        "id": "rcq3WgydukNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}